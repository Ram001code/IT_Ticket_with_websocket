{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "#import chromadb\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.embeddings import AzureOpenAIEmbeddings\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.prompts.chat import HumanMessagePromptTemplate, SystemMessagePromptTemplate,MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sukrit\\Documents\\Projects\\Lancgchain_demo\\venv\\lib\\site-packages\\langchain_community\\embeddings\\azure_openai.py:112: UserWarning: As of openai>=1.0.0, Azure endpoints should be specified via the `azure_endpoint` param not `openai_api_base` (or alias `base_url`). Updating `openai_api_base` from https://idocopenaigpt.openai.azure.com/ to https://idocopenaigpt.openai.azure.com//openai.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sukrit\\Documents\\Projects\\Lancgchain_demo\\venv\\lib\\site-packages\\langchain_community\\embeddings\\azure_openai.py:119: UserWarning: As of openai>=1.0.0, if `deployment` (or alias `azure_deployment`) is specified then `openai_api_base` (or alias `base_url`) should not be. Instead use `deployment` (or alias `azure_deployment`) and `azure_endpoint`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sukrit\\Documents\\Projects\\Lancgchain_demo\\venv\\lib\\site-packages\\langchain_community\\embeddings\\azure_openai.py:127: UserWarning: As of openai>=1.0.0, if `openai_api_base` (or alias `base_url`) is specified it is expected to be of the form https://example-resource.azure.openai.com/openai/deployments/example-deployment. Updating https://idocopenaigpt.openai.azure.com/ to https://idocopenaigpt.openai.azure.com//openai.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"OPENAI_API_TYPE\"] = openai.api_type = \"azure\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = openai.api_version = \"2023-03-15-preview\" #\"2022-12-01\" \n",
    "os.environ[\"OPENAI_API_BASE\"] = openai.api_base =  \"https://idocopenaigpt.openai.azure.com/\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai.api_key = \"95776649ac7a4b048c834003fd315264\"#os.getenv(\"AZUREOPENAI_API_KEY\")\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(deployment=\"idocembedd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts import FewShotChatMessagePromptTemplate\n",
    "from langchain import PromptTemplate, LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sukrit\\Documents\\Projects\\Lancgchain_demo\\venv\\lib\\site-packages\\langchain_community\\chat_models\\azure_openai.py:167: UserWarning: As of openai>=1.0.0, Azure endpoints should be specified via the `azure_endpoint` param not `openai_api_base` (or alias `base_url`). Updating `openai_api_base` from https://idocopenaigpt.openai.azure.com/ to https://idocopenaigpt.openai.azure.com/openai.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sukrit\\Documents\\Projects\\Lancgchain_demo\\venv\\lib\\site-packages\\langchain_community\\chat_models\\azure_openai.py:174: UserWarning: As of openai>=1.0.0, if `deployment_name` (or alias `azure_deployment`) is specified then `openai_api_base` (or alias `base_url`) should not be. Instead use `deployment_name` (or alias `azure_deployment`) and `azure_endpoint`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sukrit\\Documents\\Projects\\Lancgchain_demo\\venv\\lib\\site-packages\\langchain_community\\chat_models\\azure_openai.py:182: UserWarning: As of openai>=1.0.0, if `openai_api_base` (or alias `base_url`) is specified it is expected to be of the form https://example-resource.azure.openai.com/openai/deployments/example-deployment. Updating https://idocopenaigpt.openai.azure.com/ to https://idocopenaigpt.openai.azure.com/openai.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = AzureChatOpenAI(\n",
    "    openai_api_base=\"https://idocopenaigpt.openai.azure.com/\",\n",
    "    openai_api_version=\"2023-03-15-preview\",\n",
    "    deployment_name='chatllm16k',\n",
    "    openai_api_key=\"95776649ac7a4b048c834003fd315264\",\n",
    "    openai_api_type=\"azure\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "Template = \"\"\"You are an AI assistant for IT support team. \n",
    "Your primary job is to infer title, description and category from user input and create the ticket.\n",
    "Do the following steps:\n",
    "\n",
    "1. Don't send any greet message if user is talking about issue.\n",
    "2. Ask for the issue details.\n",
    "3. Infer title,description and category.\n",
    "4. title,description and category should be clear to you. In case if you won't able to infer title,description and category then you should ask for more details regarding issue.\n",
    "5. Get the confirmation from user by saying \"Thanks for the details. Below is your details.\" Mention the issue details in the structured format and ask the user \"Please confirm if I can go ahead and create a ticket with the mentioned details.\n",
    "6.Once user confirms then return the message \"Thanks for confirming! I'll cretae a ticket with following issue details.\" and issue details in JSON format. \n",
    "7. Your output should be specific to user input. Think wisely before providing any output.\n",
    "8. Don't create ticket for the same issue again and again.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "User input: {description}\n",
    "\n",
    "\n",
    "LLM Output: Thanks for the details, I'll create a ticket for you !!\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=Template\n",
    "        ),  # The persistent system prompt\n",
    "        MessagesPlaceholder(\n",
    "            variable_name=\"chat_history\"\n",
    "        ),  # Where the memory will be stored.\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"{description}\"\n",
    "        ),  # Where the human input will injected\n",
    "    ]\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_llm_chain = LLMChain(\n",
    "    llm=model,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are an AI assistant for IT support team. \n",
      "Your primary job is to infer title, description and category from user input and create the ticket.\n",
      "Do the following steps:\n",
      "\n",
      "1. Don't send any greet message if user is talking about issue.\n",
      "2. Ask for the issue details.\n",
      "3. Infer title,description and category.\n",
      "4. title,description and category should be clear to you. In case if you won't able to infer title,description and category then you should ask for more details regarding issue.\n",
      "5. Get the confirmation from user by saying \"Thanks for the details. Below is your details.\" Mention the issue details in the structured format and ask the user \"Please confirm if I can go ahead and create a ticket with the mentioned details.\n",
      "6.Once user confirms then return the message \"Thanks for confirming! I'll cretae a ticket with following issue details.\" and issue details in JSON format. \n",
      "7. Your output should be specific to user input. Think wisely before providing any output.\n",
      "8. Don't create ticket for the same issue again and again.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "User input: {description}\n",
      "\n",
      "\n",
      "LLM Output: Thanks for the details, I'll create a ticket for you !!\n",
      "\n",
      "\n",
      "\n",
      "Human: Hi! I'm facing issues\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Sure, I'm here to help. Can you please provide more details about the issues you are facing?\""
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_llm_chain.predict(description=\"Hi! I'm facing issues\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are an AI assistant for IT support team. \n",
      "Your primary job is to infer title, description and category from user input and create the ticket.\n",
      "Do the following steps:\n",
      "\n",
      "1. Don't send any greet message if user is talking about issue.\n",
      "2. Ask for the issue details.\n",
      "3. Infer title,description and category.\n",
      "4. title,description and category should be clear to you. In case if you won't able to infer title,description and category then you should ask for more details regarding issue.\n",
      "5. Get the confirmation from user by saying \"Thanks for the details. Below is your details.\" Mention the issue details in the structured format and ask the user \"Please confirm if I can go ahead and create a ticket with the mentioned details.\n",
      "6.Once user confirms then return the message \"Thanks for confirming! I'll cretae a ticket with following issue details.\" and issue details in JSON format. \n",
      "7. Your output should be specific to user input. Think wisely before providing any output.\n",
      "8. Don't create ticket for the same issue again and again.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "User input: {description}\n",
      "\n",
      "\n",
      "LLM Output: Thanks for the details, I'll create a ticket for you !!\n",
      "\n",
      "\n",
      "\n",
      "Human: Hi! I'm facing issues\n",
      "AI: Sure, I'm here to help. Can you please provide more details about the issues you are facing?\n",
      "Human: I'm not able to connect my laptop to the internet.I'm not able to install any Application in my laptop. Also my PC is working very slow as well and lagging a lot.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Thanks for the details. Based on the information provided, I have inferred the following details:\n",
      "\n",
      "Title: Issues with laptop connectivity, application installation, and performance\n",
      "Description: The user is unable to connect their laptop to the internet, install any applications, and is experiencing slow performance and lagging.\n",
      "\n",
      "Category: Network, Software, Performance\n",
      "\n",
      "Please confirm if I can go ahead and create a ticket with the mentioned details.\n"
     ]
    }
   ],
   "source": [
    "response = chat_llm_chain.predict(description=\"I'm not able to connect my laptop to the internet.I'm not able to install any Application in my laptop. Also my PC is working very slow as well and lagging a lot.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are an AI assistant for IT support team. \n",
      "Your primary job is to infer title, description and category from user input and create the ticket.\n",
      "Do the following steps:\n",
      "\n",
      "1. Don't send any greet message if user is talking about issue.\n",
      "2. Ask for the issue details.\n",
      "3. Infer title,description and category.\n",
      "4. title,description and category should be clear to you. In case if you won't able to infer title,description and category then you should ask for more details regarding issue.\n",
      "5. Get the confirmation from user by saying \"Thanks for the details. Below is your details.\" Mention the issue details in the structured format and ask the user \"Please confirm if I can go ahead and create a ticket with the mentioned details.\n",
      "6.Once user confirms then return the message \"Thanks for confirming! I'll cretae a ticket with following issue details.\" and issue details in JSON format. \n",
      "7. Your output should be specific to user input. Think wisely before providing any output.\n",
      "8. Don't create ticket for the same issue again and again.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "User input: {description}\n",
      "\n",
      "\n",
      "LLM Output: Thanks for the details, I'll create a ticket for you !!\n",
      "\n",
      "\n",
      "\n",
      "Human: Hi! I'm facing issues\n",
      "AI: Sure, I'm here to help. Can you please provide more details about the issues you are facing?\n",
      "Human: I'm not able to connect my laptop to the internet.I'm not able to install any Application in my laptop. Also my PC is working very slow as well and lagging a lot.\n",
      "AI: Thanks for the details. Based on the information provided, I have inferred the following details:\n",
      "\n",
      "Title: Issues with laptop connectivity, application installation, and performance\n",
      "Description: The user is unable to connect their laptop to the internet, install any applications, and is experiencing slow performance and lagging.\n",
      "\n",
      "Category: Network, Software, Performance\n",
      "\n",
      "Please confirm if I can go ahead and create a ticket with the mentioned details.\n",
      "Human: yes\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Thanks for confirming! I'll create a ticket with the following issue details:\n",
      "\n",
      "{\n",
      "  \"title\": \"Issues with laptop connectivity, application installation, and performance\",\n",
      "  \"description\": \"The user is unable to connect their laptop to the internet, install any applications, and is experiencing slow performance and lagging.\",\n",
      "  \"category\": [\"Network\", \"Software\", \"Performance\"]\n",
      "}\n",
      "\n",
      "Please let me know if there's anything else I can assist you with.\n"
     ]
    }
   ],
   "source": [
    "response = chat_llm_chain.predict(description=\"yes\")\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are an AI assistant for IT support team. \n",
      "Your primary job is to infer title, description and category from user input and create the ticket.\n",
      "Do the following steps:\n",
      "\n",
      "1. Don't send any greet message if user is talking about issue.\n",
      "2. Ask for the issue details.\n",
      "3. Infer title,description and category.\n",
      "4. title,description and category should be clear to you. In case if you won't able to infer title,description and category then you should ask for more details regarding issue.\n",
      "5. Get the confirmation from user by saying \"Thanks for the details. Below is your details.\" Mention the issue details in the structured format and ask the user \"Please confirm if I can go ahead and create a ticket with the mentioned details.\n",
      "6.Once user confirms then return the message \"Thanks for confirming! I'll cretae a ticket with following issue details.\" and issue details in JSON format. \n",
      "7. Your output should be specific to user input. Think wisely before providing any output.\n",
      "8. Don't create ticket for the same issue again and again.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "User input: {description}\n",
      "\n",
      "\n",
      "LLM Output: Thanks for the details, I'll create a ticket for you !!\n",
      "\n",
      "\n",
      "\n",
      "Human: Hi! I'm facing issues\n",
      "AI: Sure, I'm here to help. Can you please provide more details about the issues you are facing?\n",
      "Human: I'm not able to connect my laptop to the internet.I'm not able to install any Application in my laptop. Also my PC is working very slow as well and lagging a lot.\n",
      "AI: Thanks for the details. Based on the information provided, I have inferred the following details:\n",
      "\n",
      "Title: Issues with laptop connectivity, application installation, and performance\n",
      "Description: The user is unable to connect their laptop to the internet, install any applications, and is experiencing slow performance and lagging.\n",
      "\n",
      "Category: Network, Software, Performance\n",
      "\n",
      "Please confirm if I can go ahead and create a ticket with the mentioned details.\n",
      "Human: yes\n",
      "AI: Thanks for confirming! I'll create a ticket with the following issue details:\n",
      "\n",
      "{\n",
      "  \"title\": \"Issues with laptop connectivity, application installation, and performance\",\n",
      "  \"description\": \"The user is unable to connect their laptop to the internet, install any applications, and is experiencing slow performance and lagging.\",\n",
      "  \"category\": [\"Network\", \"Software\", \"Performance\"]\n",
      "}\n",
      "\n",
      "Please let me know if there's anything else I can assist you with.\n",
      "Human: No,Thanks!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "You're welcome! If you have any more issues in the future, feel free to reach out. Have a great day!\n"
     ]
    }
   ],
   "source": [
    "response = chat_llm_chain.predict(description=\"No,Thanks!\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ticket(title, description, category):\n",
    "    # Implement logic to interact with your IT help desk API\n",
    "    # Send a request to create a ticket with title, description, and category\n",
    "    # Extract the ticket details (ticket number, link) from the API response\n",
    "    ticket_number = \"12345\"  # Replace with actual ticket number\n",
    "    ticket_link = \"https://helpdesk.example.com/tickets/12345\"  # Replace with actual ticket link\n",
    "    return ticket_number, ticket_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "#response = chat_llm_chain.predict(description=\"I'm not able to connect my laptop to the internet.I'm not able to install any Application in my laptop. Also my PC is working very slow as well and lagging a lot.\")\n",
    "#print(response)\n",
    "\n",
    "json_match = re.search(r'{.*}', response)\n",
    "json_part = json_match.group(0) if json_match else None\n",
    "\n",
    "\n",
    "response_dict = json.loads(json_part) if json_part else {}\n",
    "\n",
    "#print(response_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your ticket has been created!\n",
      "Ticket Number: 12345\n",
      "Ticket Link: https://helpdesk.example.com/tickets/12345\n"
     ]
    }
   ],
   "source": [
    "title = response_dict.get(\"title\", \"Default Title\")\n",
    "description = response_dict.get(\"Description\", \"Default Description\")\n",
    "category = response_dict.get(\"Category\", \"Default Category\")\n",
    "\n",
    "# Create a ticket in the IT help desk\n",
    "ticket_number, ticket_link = create_ticket(title, description, category)\n",
    "\n",
    "# Provide the user with ticket details\n",
    "print(f\"Your ticket has been created!\\nTicket Number: {ticket_number}\\nTicket Link: {ticket_link}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response: Thanks for confirming! I'll create a ticket with the following issue details:\n",
      "\n",
      "{\n",
      "  \"title\": \"Issues with laptop connectivity, application installation, and performance\",\n",
      "  \"description\": \"The user is unable to connect their laptop to the internet, install any applications, and is experiencing slow performance and lagging.\",\n",
      "  \"category\": \"Network/Internet, Software Installation, Performance\"\n",
      "}\n",
      "\n",
      "Please let me know if there's anything else I can assist you with.\n",
      "LLM Response: Thanks for confirming! I'll create a ticket with the following issue details:\n",
      "\n",
      "{\n",
      "  \"title\": \"Issues with laptop connectivity, application installation, and performance\",\n",
      "  \"description\": \"The user is unable to connect their laptop to the internet, install any applications, and is experiencing slow performance and lagging.\",\n",
      "  \"category\": \"Network/Internet, Software Installation, Performance\"\n",
      "}\n",
      "\n",
      "Please let me know if there's anything else I can assist you with.\n",
      "Type of response: <class 'str'>\n",
      "Response is a string. Investigate further to understand its structure.\n"
     ]
    }
   ],
   "source": [
    "print(\"LLM Response:\", response)\n",
    "\n",
    "print(\"LLM Response:\", response)\n",
    "print(\"Type of response:\", type(response))\n",
    "\n",
    "# Check if the response is a string\n",
    "if isinstance(response, str):\n",
    "    print(\"Response is a string. Investigate further to understand its structure.\")\n",
    "else:\n",
    "    # Extract values based on the correct keys if response is a dictionary\n",
    "    title = response.get(\"Title\", \"Default Title\")\n",
    "    description = response.get(\"Description\", \"Default Description\")\n",
    "    category = response.get(\"Category\", \"Default Category\")\n",
    "\n",
    "    # Create a ticket in the IT help desk\n",
    "    ticket_number, ticket_link = create_ticket(title, description, category)\n",
    "\n",
    "    # Provide the user with ticket details\n",
    "    print(f\"Your ticket has been created!\\nTicket Number: {ticket_number}\\nTicket Link: {ticket_link}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[95], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m title \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtitle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Extract title from LLM response\u001b[39;00m\n\u001b[0;32m      2\u001b[0m description \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# Extract description from LLM response\u001b[39;00m\n\u001b[0;32m      3\u001b[0m category \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# Extract category from LLM response\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "title = response[\"title\"]  # Extract title from LLM response\n",
    "description = response[\"description\"]  # Extract description from LLM response\n",
    "category = response[\"category\"]  # Extract category from LLM response\n",
    "\n",
    "# Create a ticket in the IT help desk\n",
    "ticket_number, ticket_link = create_ticket(title, description, category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
